import numpy as np
import nltk
import string
import bs4 as bs
import re
import pandas as pd
import matplotlib as plt
import seaborn as sns
%matplotlib inline
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer,LancasterStemmer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix,classification_report
import ipywidgets as widgets
from ipywidgets import interact, interact_manual
df=pd.read_excel("C:/Users/sugat/Documents/Fakemain/amazon_reviews.xlsx")
df.head()
del df['DOC_ID']
del df['PRODUCT_TITLE']
del df['REVIEW_TITLE']
df.head()
sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\
df.dropna()
sns.countplot(df['RATING'])
sns.set(rc={'figure.figsize':(17,13)})
sns.barplot(x='RATING',y='PRODUCT_CATEGORY',data=df,hue='LABEL')
sns.countplot(df['LABEL'])
sns.countplot(y='LABEL',data=df,palette='coolwarm',hue='VERIFIED_PURCHASE')
cats=list(df['PRODUCT_CATEGORY'].unique())
a=widgets.Combobox(
    value='Beauty',
    placeholder='Choose a category',
    options=cats,
    description='Combobox:',
    ensure_option=True,
    disabled=False
)
display(a)
k=a.value
k
test = pd.DataFrame(df[df["PRODUCT_CATEGORY"]==k].drop('PRODUCT_CATEGORY',axis=1))
test.columns = ["LABEL","RATING","VERIFIED_PURCHASE","PRODUCT_ID","REVIEW_TEXT"]
test.reset_index(inplace=True)
test
stops = set(stopwords.words("english"))
porter = PorterStemmer()
lancaster=LancasterStemmer()
def stemSentence(sentence):
    sentence = [char for char in sentence if char not in string.punctuation]
    sentence = ''.join(sentence)
    sentence=[word for word in sentence.split() if word.lower() not in stops]
    sentence=' '.join(sentence)
    return sentence
    token_words=word_tokenize(sentence)
    token_words
    stem_sentence=[]
    for word in token_words:
        stem_sentence.append(porter.stem(word))
        stem_sentence.append(" ")
    return "".join(stem_sentence)
stemSentence('ran run running!!')
stemSentence('study studied i was studying')
test['CORPUS']=test['REVIEW_TEXT'].apply(stemSentence)
corpus = test['CORPUS']
vectorizer=CountVectorizer()
bow=vectorizer.fit_transform(corpus)
print(bow.toarray())
print(vectorizer.get_feature_names())
bow1=pd.DataFrame(bow.toarray(),columns=vectorizer.get_feature_names())
VP=pd.get_dummies(test['VERIFIED_PURCHASE'])
bow1["VERIFIED_PURCHASE"]=VP["Y"]
bow1['Fake']=test['LABEL']
X=bow1.drop('Fake',axis=1)
y=bow1['Fake']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)
rd=RandomForestClassifier(n_estimators=200)
rd.fit(X_train,y_train)
predpipe=rd.predict(X_test)
print(confusion_matrix(y_test,predpipe))
print('\n')
print(classification_report(y_test,predpipe))
predpipe=rd.predict(X_test.iloc[[0]])
predpipe
